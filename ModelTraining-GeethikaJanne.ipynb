{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59971ca5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\jupyter\\New folder\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing Required Libraries\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b9dee5d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the training and validation generators\n",
    "\n",
    "train_dir = 'data/train'\n",
    "test_dir = 'data/test'\n",
    "train_datagenerator = ImageDataGenerator(rescale=1./255)\n",
    "test_datagenerator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagenerator.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(48,48),\n",
    "        batch_size=64,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagenerator.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(48,48),\n",
    "        batch_size=64,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a264a9ed",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\jupyter\\New folder\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\jupyter\\New folder\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Building the CNN architecture\n",
    "# with four conv2D layers, two dense layers and one flatten layer\n",
    "\n",
    "recognition_model = Sequential()\n",
    "\n",
    "recognition_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
    "recognition_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "recognition_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "recognition_model.add(Dropout(0.25))\n",
    "\n",
    "recognition_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "recognition_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "recognition_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "recognition_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "recognition_model.add(Dropout(0.25))\n",
    "\n",
    "recognition_model.add(Flatten())\n",
    "recognition_model.add(Dense(1024, activation='relu'))\n",
    "recognition_model.add(Dropout(0.5))\n",
    "recognition_model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bab66114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 46, 46, 32)        320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 44, 44, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 22, 22, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 22, 22, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 20, 20, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 10, 10, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 4, 4, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 7175      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2345607 (8.95 MB)\n",
      "Trainable params: 2345607 (8.95 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Getting Model Summary\n",
    "\n",
    "recognition_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a3c30e6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Disable OpenCL\n",
    "\n",
    "cv2.ocl.setUseOpenCL(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "080a4c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.001, decay=1e-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9ec91b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define your model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Define your optimizer with learning rate and learning rate decay\n",
    "initial_learning_rate = 0.01\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0be16edc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "decay is deprecated in the new Keras optimizer, please check the docstring for valid arguments, or use the legacy optimizer, e.g., tf.keras.optimizers.legacy.Adam.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Compile Model\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m recognition_model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m, decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m),metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mC:\\jupyter\\New folder\\Lib\\site-packages\\keras\\src\\optimizers\\adam.py:110\u001b[0m, in \u001b[0;36mAdam.__init__\u001b[1;34m(self, learning_rate, beta_1, beta_2, epsilon, amsgrad, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, jit_compile, name, **kwargs)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     94\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    109\u001b[0m ):\n\u001b[1;32m--> 110\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    111\u001b[0m         name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m    112\u001b[0m         weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[0;32m    113\u001b[0m         clipnorm\u001b[38;5;241m=\u001b[39mclipnorm,\n\u001b[0;32m    114\u001b[0m         clipvalue\u001b[38;5;241m=\u001b[39mclipvalue,\n\u001b[0;32m    115\u001b[0m         global_clipnorm\u001b[38;5;241m=\u001b[39mglobal_clipnorm,\n\u001b[0;32m    116\u001b[0m         use_ema\u001b[38;5;241m=\u001b[39muse_ema,\n\u001b[0;32m    117\u001b[0m         ema_momentum\u001b[38;5;241m=\u001b[39mema_momentum,\n\u001b[0;32m    118\u001b[0m         ema_overwrite_frequency\u001b[38;5;241m=\u001b[39mema_overwrite_frequency,\n\u001b[0;32m    119\u001b[0m         jit_compile\u001b[38;5;241m=\u001b[39mjit_compile,\n\u001b[0;32m    120\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    121\u001b[0m     )\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_learning_rate(learning_rate)\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_1 \u001b[38;5;241m=\u001b[39m beta_1\n",
      "File \u001b[1;32mC:\\jupyter\\New folder\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:1084\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[1;34m(self, name, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, jit_compile, **kwargs)\u001b[0m\n\u001b[0;32m   1082\u001b[0m mesh \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmesh\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   1083\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mesh \u001b[38;5;241m=\u001b[39m mesh\n\u001b[1;32m-> 1084\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m   1085\u001b[0m     name,\n\u001b[0;32m   1086\u001b[0m     weight_decay,\n\u001b[0;32m   1087\u001b[0m     clipnorm,\n\u001b[0;32m   1088\u001b[0m     clipvalue,\n\u001b[0;32m   1089\u001b[0m     global_clipnorm,\n\u001b[0;32m   1090\u001b[0m     use_ema,\n\u001b[0;32m   1091\u001b[0m     ema_momentum,\n\u001b[0;32m   1092\u001b[0m     ema_overwrite_frequency,\n\u001b[0;32m   1093\u001b[0m     jit_compile,\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1095\u001b[0m )\n\u001b[0;32m   1096\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribution_strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_with_dtensor \u001b[38;5;241m=\u001b[39m dtensor_utils\u001b[38;5;241m.\u001b[39mrunning_with_dtensor_strategy()\n",
      "File \u001b[1;32mC:\\jupyter\\New folder\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:106\u001b[0m, in \u001b[0;36m_BaseOptimizer.__init__\u001b[1;34m(self, name, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, jit_compile, **kwargs)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variables \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_iteration_variable()\n\u001b[1;32m--> 106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_kwargs(kwargs)\n",
      "File \u001b[1;32mC:\\jupyter\\New folder\\Lib\\site-packages\\keras\\src\\optimizers\\optimizer.py:135\u001b[0m, in \u001b[0;36m_BaseOptimizer._process_kwargs\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m legacy_kwargs:\n\u001b[1;32m--> 135\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    136\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is deprecated in the new Keras optimizer, please \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    137\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheck the docstring for valid arguments, or use the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    138\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegacy optimizer, e.g., \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    139\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.keras.optimizers.legacy.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    140\u001b[0m         )\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    143\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid argument, kwargs should be empty \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    144\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for `optimizer_experimental.Optimizer`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    145\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: decay is deprecated in the new Keras optimizer, please check the docstring for valid arguments, or use the legacy optimizer, e.g., tf.keras.optimizers.legacy.Adam."
     ]
    }
   ],
   "source": [
    "# Compile Model\n",
    "\n",
    "recognition_model.compile(loss='categorical_crossentropy',optimizer=Adam(learning_rate=0.0001, decay=1e-6),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d870bdaf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m recognition_model_info \u001b[38;5;241m=\u001b[39m recognition_model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m      4\u001b[0m         train_generator,\n\u001b[0;32m      5\u001b[0m         steps_per_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m28709\u001b[39m \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m64\u001b[39m,\n\u001b[0;32m      6\u001b[0m         epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m,\n\u001b[0;32m      7\u001b[0m         validation_data\u001b[38;5;241m=\u001b[39mtest_generator,\n\u001b[0;32m      8\u001b[0m         validation_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7178\u001b[39m \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m64\u001b[39m)\n",
      "File \u001b[1;32mC:\\jupyter\\New folder\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\jupyter\\New folder\\Lib\\site-packages\\keras\\src\\engine\\training.py:3983\u001b[0m, in \u001b[0;36mModel._assert_compile_was_called\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3977\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_assert_compile_was_called\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   3978\u001b[0m     \u001b[38;5;66;03m# Checks whether `compile` has been called. If it has been called,\u001b[39;00m\n\u001b[0;32m   3979\u001b[0m     \u001b[38;5;66;03m# then the optimizer is set. This is different from whether the\u001b[39;00m\n\u001b[0;32m   3980\u001b[0m     \u001b[38;5;66;03m# model is compiled\u001b[39;00m\n\u001b[0;32m   3981\u001b[0m     \u001b[38;5;66;03m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[39;00m\n\u001b[0;32m   3982\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_compiled:\n\u001b[1;32m-> 3983\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   3984\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must compile your model before \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3985\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining/testing. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3986\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `model.compile(optimizer, loss)`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3987\u001b[0m         )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "recognition_model_info = recognition_model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=28709 // 64,\n",
    "        epochs=60,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=7178 // 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197e09d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the trained Model Weights\n",
    "\n",
    "recognition_model.save_weights('recognition_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73855370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize history for accuracy\n",
    "\n",
    "plt.title('Model Accuracy')\n",
    "plt.plot(recognition_model_info.history['accuracy'])\n",
    "plt.plot(recognition_model_info.history['val_accuracy'])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Summarize history for loss\n",
    "\n",
    "plt.title('Model Loss')\n",
    "plt.plot(recognition_model_info.history['loss'])\n",
    "plt.plot(recognition_model_info.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53d2eff6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Facial emotion Dictonary with values\n",
    "\n",
    "facial_dict = {0: \"Angry\", 1: \"Disgusted\", 2: \"Fearful\", 3: \"Happy\", 4: \"Neutral\", 5: \"Sad\", 6: \"Surprised\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fe7ace4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Start the webcam feed\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    # Find haar cascade to draw bounding box around face\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    bounding_box = cv2.CascadeClassifier('haarcascades_cuda/haarcascade_frontalface_default.xml')\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    num_faces = bounding_box.detectMultiScale(gray_frame,scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "    for (x, y, w, h) in num_faces:\n",
    "        cv2.rectangle(frame, (x, y-50), (x+w, y+h+10), (255, 0, 0), 2)\n",
    "        roi_gray_frame = gray_frame[y:y + h, x:x + w]\n",
    "        cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray_frame, (48, 48)), -1), 0)\n",
    "        facial_prediction = recognition_model.predict(cropped_img)\n",
    "        maxindex = int(np.argmax(facial_prediction))\n",
    "        cv2.putText(frame, facial_dict[maxindex], (x+20, y-60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('Video', cv2.resize(frame,(1200,860),interpolation = cv2.INTER_CUBIC))\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46fefac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
