{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51e422c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\jupyter\\new folder\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\jupyter\\new folder\\lib\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\jupyter\\new folder\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\jupyter\\new folder\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\jupyter\\new folder\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\jupyter\\new folder\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\jupyter\\new folder\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\jupyter\\new folder\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\jupyter\\new folder\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\jupyter\\new folder\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\jupyter\\new folder\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\jupyter\\new folder\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\jupyter\\new folder\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\jupyter\\new folder\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in c:\\jupyter\\new folder\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\jupyter\\new folder\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\jupyter\\new folder\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\jupyter\\new folder\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\jupyter\\new folder\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\jupyter\\new folder\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\jupyter\\new folder\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.60.1)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\jupyter\\new folder\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\jupyter\\new folder\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\jupyter\\new folder\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\jupyter\\new folder\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\jupyter\\new folder\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.27.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\jupyter\\new folder\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\jupyter\\new folder\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\jupyter\\new folder\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\jupyter\\new folder\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\jupyter\\new folder\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\jupyter\\new folder\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\jupyter\\new folder\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\jupyter\\new folder\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\jupyter\\new folder\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\jupyter\\new folder\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\jupyter\\new folder\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\jupyter\\new folder\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\jupyter\\new folder\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\jupyter\\new folder\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\jupyter\\new folder\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\jupyter\\new folder\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d68033da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\jupyter\\New folder\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing Required Libraries\n",
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42a56400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\jupyter\\New folder\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\jupyter\\New folder\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build the convolution network architecture\n",
    "\n",
    "face_model = Sequential()\n",
    "face_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
    "face_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "face_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "face_model.add(Dropout(0.25))\n",
    "face_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "face_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "face_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "face_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "face_model.add(Dropout(0.25))\n",
    "face_model.add(Flatten())\n",
    "face_model.add(Dense(1024, activation='relu'))\n",
    "face_model.add(Dropout(0.5))\n",
    "face_model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f64f3610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved weights\n",
    "\n",
    "face_model.load_weights('recognition_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abeed557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable OpenCL\n",
    "\n",
    "cv2.ocl.setUseOpenCL(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5df98dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Datasets Dictionaries\n",
    "\n",
    "facial_dict = {0: \"   Angry   \", 1: \"Disgusted\", 2: \"  Fearful  \", 3: \"   Happy   \", 4: \"  Neutral  \", 5: \"    Sad    \", 6: \"Surprised\"}\n",
    "emojis_dict = {0:\"emojis/angry.png\", 1:\"emojis/disgusted.png\", 2:\"emojis/fearful.png\", 3:\"emojis/happy.png\", 4:\"emojis/neutral.png\", 5:\"emojis/sad.png\", 6:\"emojis/surprised.png\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44c56df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables for \n",
    "\n",
    "global last_frame1                         \n",
    "last_frame1 = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "global cap1\n",
    "show_text=[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ffc11f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get face captured and recognize emotion\n",
    "\n",
    "def Capture_Image():\n",
    "    global cap1\n",
    "    cap1 = cv2.VideoCapture(0)\n",
    "    if not cap1.isOpened():\n",
    "        print(\"Unable to open the camera !\")\n",
    "    flag1, frame1 = cap1.read()\n",
    "    frame1 = cv2.resize(frame1,(600,500))\n",
    "    # It will detect the face in the video and bound it with a rectangular box\n",
    "    bound_box = cv2.CascadeClassifier('haarcascades_cuda/haarcascade_frontalface_default.xml')\n",
    "    gray_frame = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    n_faces = bound_box.detectMultiScale(gray_frame,scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "    for (x, y, w, h) in n_faces:\n",
    "        cv2.rectangle(frame1, (x, y-50), (x+w, y+h+10), (255, 0, 0), 2)\n",
    "        roi_frame = gray_frame[y:y + h, x:x + w]\n",
    "        crop_img = np.expand_dims(np.expand_dims(cv2.resize(roi_frame, (48, 48)), -1), 0)\n",
    "        prediction = face_model.predict(crop_img)\n",
    "        maxindex = int(np.argmax(prediction))\n",
    "        cv2.putText(frame1, facial_dict[maxindex], (x+20, y-60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        show_text[0]=maxindex\n",
    "\n",
    "    if flag1 is None:\n",
    "        print (\"Error!\")\n",
    "\n",
    "    elif flag1:\n",
    "        global last_frame1\n",
    "        last_frame1 = frame1.copy()\n",
    "        pic = cv2.cvtColor(last_frame1, cv2.COLOR_BGR2RGB) #to store the image   \n",
    "        img = Image.fromarray(pic)\n",
    "        imgtk = ImageTk.PhotoImage(image=img)\n",
    "        lmain.imgtk = imgtk\n",
    "        lmain.configure(image=imgtk)\n",
    "        lmain.after(10, Capture_Image)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09b62a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for showing Emoji According to Facial Expression\n",
    "\n",
    "def Get_Emoji():\n",
    "    frame2=cv2.imread(emojis_dict[show_text[0]])\n",
    "    pic2=cv2.cvtColor(frame2,cv2.COLOR_BGR2RGB)\n",
    "    img2=Image.fromarray(frame2)\n",
    "    imgtk2=ImageTk.PhotoImage(image=img2)\n",
    "    lmain2.imgtk2=imgtk2\n",
    "    lmain3.configure(text=facial_dict[show_text[0]],font=('arial',45,'bold'))\n",
    "    lmain2.configure(image=imgtk2)\n",
    "    lmain2.after(10, Get_Emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90634c92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m root[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbg\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     22\u001b[0m exitbutton \u001b[38;5;241m=\u001b[39m Button(root, text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuit\u001b[39m\u001b[38;5;124m'\u001b[39m,fg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m,command\u001b[38;5;241m=\u001b[39mroot\u001b[38;5;241m.\u001b[39mdestroy,font\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marial\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;241m25\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbold\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39mpack(side \u001b[38;5;241m=\u001b[39m BOTTOM)\n\u001b[1;32m---> 23\u001b[0m Capture_Image()\n\u001b[0;32m     24\u001b[0m Get_Emoji()\n\u001b[0;32m     25\u001b[0m root\u001b[38;5;241m.\u001b[39mmainloop()\n",
      "Cell \u001b[1;32mIn[8], line 9\u001b[0m, in \u001b[0;36mCapture_Image\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to open the camera !\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m flag1, frame1 \u001b[38;5;241m=\u001b[39m cap1\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m----> 9\u001b[0m frame1 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(frame1,(\u001b[38;5;241m600\u001b[39m,\u001b[38;5;241m500\u001b[39m))\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# It will detect the face in the video and bound it with a rectangular box\u001b[39;00m\n\u001b[0;32m     11\u001b[0m bound_box \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mCascadeClassifier(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhaarcascades_cuda/haarcascade_frontalface_default.xml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "# GUI Window to show captured image with emoji\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    root=tk.Tk()  \n",
    "    heading = Label(root,bg='black')\n",
    "    heading.pack()\n",
    "    # To label the output\n",
    "    heading2=Label(root,text=\"Emojify\",pady=20, font=('arial',45,'bold'),bg='black',fg='#CDCDCD')                                \n",
    "    heading2.pack()\n",
    "    lmain = tk.Label(master=root,padx=50,bd=10)\n",
    "    lmain2 = tk.Label(master=root,bd=10)\n",
    "    lmain3=tk.Label(master=root,bd=10,fg=\"#CDCDCD\",bg='black')\n",
    "    lmain.pack(side=LEFT)\n",
    "    lmain.place(x=50,y=250)\n",
    "    lmain3.pack()\n",
    "    lmain3.place(x=960,y=250)\n",
    "    lmain2.pack(side=RIGHT)\n",
    "    lmain2.place(x=900,y=350)\n",
    "    root.title(\"Emojify\")           \n",
    "    root.geometry(\"1400x900+100+10\")\n",
    "    root['bg']='black'\n",
    "    exitbutton = Button(root, text='Quit',fg=\"red\",command=root.destroy,font=('arial',25,'bold')).pack(side = BOTTOM)\n",
    "    Capture_Image()\n",
    "    Get_Emoji()\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27591d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
